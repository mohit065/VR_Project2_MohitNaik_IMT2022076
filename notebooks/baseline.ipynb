{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from evaluate import load as load_metric\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Configuration\n",
    "VQA_CSV       = \"../data/vqa.csv\"\n",
    "CURATED_DIR   = \"../data/curated_images\"\n",
    "PRED_CSV      = \"../data/predictions.csv\"\n",
    "SAMPLE_SIZE   = 10000\n",
    "IMAGE_SIZE    = (256, 256)\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED          = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59117120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load and sample\n",
    "df = pd.read_csv(VQA_CSV)\n",
    "df_sample = df.sample(n=SAMPLE_SIZE, random_state=SEED).reset_index(drop=True)\n",
    "questions = df_sample[[\"filename\", \"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load BLIP-VQA model & processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de45ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prepare metrics\n",
    "bertscore = load_metric(\"bertscore\")\n",
    "rouge     = load_metric(\"rouge\")\n",
    "meteor    = load_metric(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Inference loop\n",
    "predictions = []\n",
    "references  = []\n",
    "\n",
    "for _, row in tqdm(questions.iterrows(), total=len(questions), desc=\"VQA Inference\"):\n",
    "    fn, q, a = row[\"filename\"], row[\"question\"], row[\"answer\"]\n",
    "    img_path = os.path.join(CURATED_DIR, fn)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\").resize(IMAGE_SIZE)\n",
    "    except:\n",
    "        predictions.append(\"\")\n",
    "        references.append(a.lower())\n",
    "        continue\n",
    "\n",
    "    inputs = processor(images=img, text=q, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(**inputs, max_new_tokens=5)\n",
    "    pred = processor.decode(out_ids[0], skip_special_tokens=True).strip().lower()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(a.lower())\n",
    "\n",
    "n = len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact match\n",
    "exact_matches = [p == r for p, r in zip(predictions, references)]\n",
    "exact_acc = sum(exact_matches) / n\n",
    "\n",
    "# Substring match\n",
    "substr_matches = [(p in r) or (r in p) for p, r in zip(predictions, references)]\n",
    "substr_acc = sum(substr_matches) / n\n",
    "\n",
    "# Exact F1\n",
    "tp = sum(exact_matches)\n",
    "fp = n - tp\n",
    "fn = n - tp\n",
    "exact_prec = tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "exact_rec  = tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "exact_f1   = 2 * exact_prec * exact_rec / (exact_prec + exact_rec) if (exact_prec + exact_rec) > 0 else 0.0\n",
    "\n",
    "# Substring F1\n",
    "tp_s = sum(substr_matches)\n",
    "fp_s = n - tp_s\n",
    "fn_s = n - tp_s\n",
    "substr_prec = tp_s / (tp_s + fp_s) if tp_s + fp_s > 0 else 0.0\n",
    "substr_rec  = tp_s / (tp_s + fn_s) if tp_s + fn_s > 0 else 0.0\n",
    "substr_f1   = 2 * substr_prec * substr_rec / (substr_prec + substr_rec) if (substr_prec + substr_rec) > 0 else 0.0\n",
    "\n",
    "# Token-level macro F1\n",
    "token_precisions, token_recalls, token_f1s = [], [], []\n",
    "for p, r in zip(predictions, references):\n",
    "    ptoks, rtoks = p.split(), r.split()\n",
    "    if not ptoks or not rtoks:\n",
    "        token_precisions.append(0.0)\n",
    "        token_recalls.append(0.0)\n",
    "        token_f1s.append(0.0)\n",
    "        continue\n",
    "    inter = len(set(ptoks) & set(rtoks))\n",
    "    prec = inter / len(ptoks)\n",
    "    rec  = inter / len(rtoks)\n",
    "    f1   = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "    token_precisions.append(prec)\n",
    "    token_recalls.append(rec)\n",
    "    token_f1s.append(f1)\n",
    "\n",
    "macro_token_prec = sum(token_precisions) / n\n",
    "macro_token_rec  = sum(token_recalls) / n\n",
    "macro_token_f1   = sum(token_f1s) / n\n",
    "\n",
    "# Levenshtein similarity\n",
    "lev_scores = [difflib.SequenceMatcher(None, p, r).ratio() for p, r in zip(predictions, references)]\n",
    "avg_lev = sum(lev_scores) / n\n",
    "\n",
    "# BERTScore F1\n",
    "bs = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "bert_f1 = sum(bs[\"f1\"]) / n\n",
    "\n",
    "# ROUGE-L F1\n",
    "rg = rouge.compute(predictions=predictions, references=references)\n",
    "rouge1 = rg[\"rouge1\"]\n",
    "rougeL = rg[\"rougeL\"]\n",
    "\n",
    "# METEOR\n",
    "meteor_s = meteor.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "\n",
    "# BLEU-1 to BLEU-4 via NLTK\n",
    "refs_for_bleu = [[r.split()] for r in references]\n",
    "preds_for_bleu = [p.split() for p in predictions]\n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "bleu1 = corpus_bleu(refs_for_bleu, preds_for_bleu, weights=(1, 0, 0, 0), smoothing_function=smooth)\n",
    "bleu2 = corpus_bleu(refs_for_bleu, preds_for_bleu, weights=(0.5, 0.5, 0, 0), smoothing_function=smooth)\n",
    "bleu3 = corpus_bleu(refs_for_bleu, preds_for_bleu, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smooth)\n",
    "bleu4 = corpus_bleu(refs_for_bleu, preds_for_bleu, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Print all metrics\n",
    "print(f\"Exact Match Acc         : {exact_acc:.4f}\")\n",
    "print(f\"Substring Match Acc     : {substr_acc:.4f}\")\n",
    "print(f\"Exact F1                : {exact_f1:.4f}\")\n",
    "print(f\"Substring F1            : {substr_f1:.4f}\")\n",
    "print(f\"Token-level Macro F1    : {macro_token_f1:.4f}\")\n",
    "print(f\"BERTScore F1            : {bert_f1:.4f}\")\n",
    "print(f\"ROUGE-1 F1              : {rouge1:.4f}\")\n",
    "print(f\"ROUGE-L F1              : {rougeL:.4f}\")\n",
    "print(f\"BLEU-1                  : {bleu1:.4f}\")\n",
    "print(f\"BLEU-2                  : {bleu2:.4f}\")\n",
    "print(f\"BLEU-3                  : {bleu3:.4f}\")\n",
    "print(f\"BLEU-4                  : {bleu4:.4f}\")\n",
    "print(f\"Levenshtein Similarity  : {avg_lev:.4f}\")\n",
    "print(f\"METEOR                  : {meteor_s:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e84173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Save predictions\n",
    "df_sample[\"prediction\"] = predictions\n",
    "df_sample.to_csv(PRED_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
