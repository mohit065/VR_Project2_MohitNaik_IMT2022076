{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21116c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Config\n",
    "SRC_PATH = '../data/images/metadata/images.csv'\n",
    "IMAGE_SRC_DIR = '../data/images/small'\n",
    "IMAGE_DEST_DIR = '../data/curated_images'\n",
    "DEST_PATH = '../data/csvs/curated.csv'\n",
    "\n",
    "N_TOTAL = 10000\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "# Read images metadata CSV\n",
    "images_df = pd.read_csv(SRC_PATH)\n",
    "metadata_lookup = {}\n",
    "\n",
    "# Helper functions\n",
    "def extract_field(data, key, inner_key='value'):\n",
    "    if isinstance(data.get(key), list) and data[key]:\n",
    "        first = data[key][0]\n",
    "        if 'language_tag' in first and not first['language_tag'].startswith('en_'):\n",
    "            return None\n",
    "        return first.get(inner_key, None)\n",
    "    return None\n",
    "\n",
    "def extract_keywords(data):\n",
    "    if isinstance(data.get('item_keywords'), list):\n",
    "        keywords = [\n",
    "            k['value'].strip().lower()\n",
    "            for k in data['item_keywords']\n",
    "            if 'language_tag' not in k or k['language_tag'].startswith('en_')\n",
    "        ]\n",
    "        seen = set()\n",
    "        return ', '.join([k for k in keywords if not (k in seen or seen.add(k))])\n",
    "    return None\n",
    "\n",
    "def get_metadata(image_id, field):\n",
    "    return metadata_lookup.get(image_id, {}).get(field)\n",
    "\n",
    "# Build metadata lookup from JSON listings\n",
    "json_files = sorted(glob.glob('../data/listings/metadata/listings_*.json'))\n",
    "for file in tqdm(json_files, desc=\"Parsing listings\", unit=\"file\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            main_id = record.get('main_image_id')\n",
    "            if main_id:\n",
    "                metadata_lookup[main_id] = {\n",
    "                    'name': extract_field(record, 'item_name'),\n",
    "                    'product_type': extract_field(record, 'product_type'),\n",
    "                    'color': extract_field(record, 'color'),\n",
    "                    'keywords': extract_keywords(record)\n",
    "                }\n",
    "\n",
    "# Attach metadata to images_df\n",
    "images_df['name'] = images_df['image_id'].apply(lambda x: get_metadata(x, 'name'))\n",
    "images_df['product_type'] = images_df['image_id'].apply(lambda x: get_metadata(x, 'product_type'))\n",
    "images_df['color'] = images_df['image_id'].apply(lambda x: get_metadata(x, 'color'))\n",
    "images_df['keywords'] = images_df['image_id'].apply(lambda x: get_metadata(x, 'keywords'))\n",
    "\n",
    "# Filter out unwanted IDs and rows missing metadata\n",
    "images_df = images_df[~images_df['image_id'].isin(['518Dk4FOzZL', '719hoe+OvIL', '71Qbh8wmhnL'])]\n",
    "images_df.dropna(subset=['name', 'product_type', 'color', 'keywords'], inplace=True)\n",
    "\n",
    "# Only ASCII lowercase in all metadata\n",
    "is_ascii = lambda text: isinstance(text, str) and text.isascii()\n",
    "for col in ['name', 'product_type', 'color']:\n",
    "    images_df = images_df[images_df[col].apply(is_ascii)]\n",
    "\n",
    "for col in ['name', 'product_type', 'color', 'keywords']:\n",
    "    images_df[col] = images_df[col].str.lower()\n",
    "\n",
    "# Balance out phone cases and non-cases\n",
    "non_case_df = images_df[images_df['product_type'] != 'cellular_phone_case']\n",
    "case_df = images_df[images_df['product_type'] == 'cellular_phone_case']\n",
    "case_sample = case_df.sample(n=min(N_TOTAL - len(non_case_df), len(case_df)))\n",
    "filtered_df = pd.concat([non_case_df, case_sample], ignore_index=True)\n",
    "\n",
    "# Sort by original path\n",
    "filtered_df = filtered_df.sort_values(by='path').reset_index(drop=True)\n",
    "print(f\"Final filtered dataset size: {len(filtered_df)}\")\n",
    "\n",
    "# Derive filename and resize+copy images\n",
    "os.makedirs(IMAGE_DEST_DIR, exist_ok=True)\n",
    "filtered_df['image_name'] = filtered_df['path'].apply(os.path.basename)\n",
    "\n",
    "for _, row in tqdm(filtered_df.iterrows(), total=len(filtered_df), desc=\"Resizing & copying images\"):\n",
    "    src = os.path.normpath(os.path.join(IMAGE_SRC_DIR, row['path']))\n",
    "    dst = os.path.join(IMAGE_DEST_DIR, row['image_name'])\n",
    "    with Image.open(src) as img:\n",
    "        resized = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "        resized.save(dst)\n",
    "\n",
    "# Write out curated CSV\n",
    "output_df = filtered_df[['image_name', 'name', 'product_type', 'color', 'keywords']]\n",
    "output_df.to_csv(DEST_PATH, index=False)\n",
    "print(f\"Saved {len(output_df)} entries to {DEST_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
